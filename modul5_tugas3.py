# -*- coding: utf-8 -*-
"""modul5_tugas3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F9QQ0_IOnkzPY8fQDtHZsZ3CyzZcLlgE
"""

!pip install scikit-learn

!pip install pytorch-tabnet scikit-learn

#Importing Libary
import numpy as np
from sklearn.impute import KNNImputer
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import tensorflow as tf
import logging
from sklearn.preprocessing import StandardScaler
tf.get_logger().setLevel(logging.ERROR)
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.model_selection import train_test_split

df = pd.read_csv("income.csv")
df.head()

df.info()

import matplotlib.pyplot as plt

figure, axis = plt.subplots(1, 2, figsize=(10,4))

axis[0].hist(df[df['income_>50K'] == 1]['age'], bins=10,color='green', alpha=0.7)
axis[0].set_xlabel('Age')
axis[0].set_title('Income more than 50,000')

axis[1].hist(df[df['income_>50K'] == 0]['age'], bins=10,color='yellow', alpha=0.7)
axis[1].set_xlabel('Age')
axis[1].set_title('Income less than 50,000')

import seaborn as sns

plt.figure(figsize=(8, 6))
sns.countplot(x='gender', hue='income_>50K', data=df, palette='Set2');

age = df['age'].value_counts()

plt.figure(figsize=(10, 5))
plt.style.use('fivethirtyeight')
sns.distplot(df['age'], bins=20)
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Number of people')
plt.show()

edu_num= df['educational-num'].value_counts()
plt.style.use('ggplot')
sns.set_style("whitegrid")
sns.barplot(x=edu_num.index, y= edu_num.values, palette='husl');
plt.xlabel('Year of education');
plt.ylabel('Number of people');

marial_status = df['marital-status'].value_counts()
plt.figure(figsize=(10, 7))

plt.style.use('default')
plt.pie(marial_status,labels=marial_status.index,autopct='%1.1f%%',shadow=True,textprops = {'fontsize': 6,'weight': 'bold'}
);
plt.legend(loc="center left")
plt.legend(prop={'size': 7})

plt.axis('equal')  ;

df['educational-num_category'] = pd.cut(df['educational-num'], bins=8)  # You can adjust the number of bins

# Create an Aggregated Bar Plot
plt.figure(figsize=(12, 8))
sns.barplot(x='educational-num_category', y='educational-num', hue='education', data=df, ci=None, palette='Set1')

# Add labels and title
plt.xlabel('Educational Number Category')
plt.ylabel('Average Educational Number')
plt.title('Aggregated Bar Plot of Educational Number by Education Level')

df.drop('educational-num_category',axis=1, inplace = True)

df = pd.concat([df.drop('occupation', axis=1), pd.get_dummies(df.occupation).add_prefix('occupation_')], axis=1)
df = pd.concat([df.drop('workclass', axis=1), pd.get_dummies(df.workclass).add_prefix('workclass_')], axis=1)
df = df.drop('education', axis=1)
df = pd.concat([df.drop('marital-status', axis=1), pd.get_dummies(df['marital-status']).add_prefix('marital-status_')], axis=1)
df = pd.concat([df.drop('relationship', axis=1), pd.get_dummies(df.relationship).add_prefix('relationship_')], axis=1)
df = pd.concat([df.drop('race', axis=1), pd.get_dummies(df.race).add_prefix('race_')], axis=1)
df = pd.concat([df.drop('native-country', axis=1), pd.get_dummies(df['native-country']).add_prefix('native-country_')], axis=1)
df['gender'] = df['gender'].apply(lambda x: 1 if x == 'Male' else 0)

df.drop('fnlwgt', axis = 1, inplace=True)
df = df.replace('?', np.nan)

selected_columns = ['capital-gain', 'hours-per-week', 'income_>50K']
df2 = df[selected_columns]

def _df(data):
    # Membuat DataFrame dari data yang diberikan.
    df2 = pd.DataFrame(data)

    # Iterasi melalui setiap kolom dalam DataFrame yang baru dibuat.
    for c in range(df2.shape[1]):
        # Membuat kamus (dictionary) yang akan digunakan untuk pemetaan nama kolom ke indeks.
        mapping = {df2.columns[c]: c}

        # Mengganti nama kolom dengan indeks kolom menggunakan kamus mapping.
        df2 = df2.rename(columns=mapping)

    # Mengembalikan DataFrame yang telah dimodifikasi.
    return df2

# Set X dan y variable
X = df2.drop(columns=["income_>50K"])
y = df2["income_>50K"]

X = KNNImputer().fit_transform(X)
data = _df(StandardScaler().fit_transform(np.column_stack((X, y))))

class Gan():

    def __init__(self, data):
        # Inisialisasi objek GAN dengan data yang akan digunakan
        self.data = data
        self.n_epochs = 200  # Jumlah epoch pelatihan GAN

    # Fungsi untuk menghasilkan noise dalam bentuk matriks
    def _noise(self):
        noise = np.random.normal(0, 1, self.data.shape)
        return noise

    # Fungsi untuk menginisialisasi Model Generator
    def _generator(self):
        model = tf.keras.Sequential(name="Generator_model")
        # Layer pertama dengan 15 neuron, aktivasi ReLU
        model.add(tf.keras.layers.Dense(15, activation='relu',
                                        kernel_initializer='he_uniform',
                                        input_dim=self.data.shape[1]))
        # Layer kedua dengan 30 neuron, aktivasi ReLU
        model.add(tf.keras.layers.Dense(30, activation='relu'))
        # Layer output dengan jumlah neuron sesuai dengan dimensi data asli, aktivasi linear
        model.add(tf.keras.layers.Dense(
            self.data.shape[1], activation='linear'))

        return model

    # Fungsi untuk menginisialisasi Model Discriminator
    def _discriminator(self):
        model = tf.keras.Sequential(name="Discriminator_model")
        # Layer pertama dengan 25 neuron, aktivasi ReLU
        model.add(tf.keras.layers.Dense(25, activation='relu',
                                        kernel_initializer='he_uniform',
                                        input_dim=self.data.shape[1]))
        # Layer kedua dengan 50 neuron, aktivasi ReLU
        model.add(tf.keras.layers.Dense(50, activation='relu'))
        # Layer keluaran dengan satu neuron (binary), aktivasi sigmoid
        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        # Compile model dengan binary_crossentropy loss dan optimizer 'adam'
        model.compile(loss='binary_crossentropy',
                      optimizer='adam',
                      metrics=['accuracy'])
        return model

    # Fungsi untuk menginisialisasi model GAN yang menggabungkan Generator dan Discriminator
    def _GAN(self, generator, discriminator):
        discriminator.trainable = False  # Dalam GAN, Discriminator tidak akan di-train ketika Generator di-train
        generator.trainable = True

        # Pembuatan model GAN
        model = tf.keras.Sequential(name="GAN")
        model.add(generator)
        model.add(discriminator)

        # Compile model dengan binary_crossentropy loss dan optimizer 'adam'
        model.compile(loss='binary_crossentropy', optimizer='adam')
        return model

    # Fungsi untuk melatih generator dan discriminator
    def train(self, generator, discriminator, gan):

        for epoch in range(self.n_epochs):

            # Train discriminator
            generated_data = generator.predict(self._noise())  # Menghasilkan data palsu dengan Generator
            labels = np.concatenate([np.ones(self.data.shape[0]), np.zeros(self.data.shape[0])])
            X = np.concatenate([self.data, generated_data])  # Gabungkan data asli dan palsu
            discriminator.trainable = True  # Biarkan Discriminator di-train
            d_loss , _ = discriminator.train_on_batch(X, labels)  # Train Discriminator pada batch X dengan label

            # Train generator
            noise = self._noise()  # Hasilkan noise
            g_loss = gan.train_on_batch(noise, np.ones(self.data.shape[0]))  # Train Generator dengan noise

            # Cetak hasil pelatihan Discriminator dan Generator
            print('>%d, d1=%.3f, d2=%.3f' %(epoch+1, d_loss, g_loss))

        return generator  # Kembalikan model Generator setelah pelatihan selesai

# Training GAN dengan 200 epochs

model = Gan(data=data)
generator = model._generator()
descriminator = model._discriminator()
gan_model = model._GAN(generator=generator, discriminator=descriminator)
trained_model = model.train(
    generator=generator, discriminator=descriminator, gan=gan_model)

# Menggunakan Model Generator yang telah dilatih untuk menghasilkan data baru dengan penambahan noise.
noise = np.random.normal(0, 1, data.shape)
new_data = _df(data=trained_model.predict(noise))

# Data lama
old_data = df[selected_columns]

# Noise
noise = np.random.normal(0, 1, old_data.shape)

# Menggunakan model generator
new_data_array = trained_model.predict(noise)

# Konversi hasil prediksi menjadi DataFrame
new_data = pd.DataFrame(data=new_data_array, columns=old_data.columns)  # asumsi nama kolom sama dengan data lama

# Merging data lama dengan data baru
merged_data = pd.concat([old_data, new_data], ignore_index=True)

# Hasil akhir
merged_data.head()

# Membagi dataset menjadi data pelatihan dan pengujian

train_df, test_df = train_test_split(merged_data, test_size=0.2, random_state=42)

from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score



# Encode categorical variables
label_encoder = LabelEncoder()


# Splitting the data into training and testing sets
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Instantiate TabNetClassifier
clf = TabNetClassifier()

# Train the model
clf.fit(
    X_train=train_df.drop('income_>50K', axis=1).values,
    y_train=train_df['income_>50K'].values,
    eval_set=[(test_df.drop('income_>50K', axis=1).values, test_df['income_>50K'].values)]
)

# Make predictions on the test set
predictions = clf.predict(test_df.drop('income_>50K', axis=1).values)

# Calculate accuracy using scikit-learn's accuracy_score
accuracy = accuracy_score(test_df['income_>50K'].values, predictions)
print(f'Accuracy: {accuracy}')

# Melakukan prediksi pada data pengujian
predictions = clf.predict(test_df.drop('income_>50K', axis=1).values)

# Mengkonversi prediksi menjadi label (0 atau 1)
predicted_labels = np.round(predictions).flatten().astype(int)

# Menampilkan hasil prediksi
print("Hasil prediksi:")
print(predicted_labels)

# Menampilkan laporan klasifikasi
target_names = ['income_<50K', 'income_>50K']
print("\nLaporan Klasifikasi:")
print(classification_report(test_df['income_>50K'].values, predicted_labels, target_names=target_names))